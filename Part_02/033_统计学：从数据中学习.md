# 统计学：从数据中学习
*推断、估计与假设检验*

1747年，James Lind 在索尔兹伯里号军舰上进行了一项划时代的实验。他把十二名坏血病患者分成六组，分别给予不同的治疗：苹果酒、硫酸、醋、海水、大蒜芥末膏，或者两个橙子加一个柠檬。不出六日，吃柑橘的两名水手便已痊愈。Lind 从有限的数据中发现了真相。

但这个"试验"只有十二人，没有随机分组，没有盲法，没有统计分析。他的结论到底有多可靠？当一项现代临床试验显示药物组有效率60%、安慰剂组45%时，我们该有多大把握？如果你公司上季度销售额增长15%，这是真正的业绩改善还是随机波动？当一项心理学研究报告"冥想显著降低焦虑，p < 0.05"时，这意味着什么——又有什么是它*没有*告诉你的？

这些问题的共同结构是：我们观察到有限的数据（一个样本、一次试验），却想从中得出关于更大范围的结论（药物对所有患者的疗效、公司的真实业绩）。这就是**统计推断**的核心——如何从不完整的信息中认识世界。

统计学提供了量化不确定性的数学框架。但它的精髓不是公式，而是一种思维方式：如何看待证据，理解不确定性，认识数据的局限。理解这种思维，远比记住任何具体检验更重要。

**核心要义**：统计推断无法消除不确定性，只能量化它。方法只有在假设成立时才有效，理解假设比计算更关键。最深刻的统计思维，在于理解数据能告诉我们什么、不能告诉我们什么，以及为什么。

## 从样本到总体：不确定性的来源

假设你想知道某国成年人的平均身高。你测量了1000人的样本，均值是170厘米。你能得出什么结论？

样本给你确切的信息：这1000人平均170厘米。但你想了解的是总体，而在这一点上，不确定性无法消除。总体均值可能是170厘米，也可能是169或171.5厘米。不同样本会给出不同答案。统计推断的作用不是消除这种不确定性，而是告诉你：样本结果可能与真值相差多少。

这种量化需要一个关键假设：样本必须具有**代表性**。如果你测量的是1000名篮球运动员，结果几乎无法说明一般人群。如果你在工作时间通过固定电话调查，你会遗漏在职人员、年轻人和只用手机的人群——你的"代表性"民调可能严重失真。

1936年《文学文摘》的民调是个警世案例。杂志调查了240万人——样本量惊人——预测 Alf Landon 将以压倒性优势击败 Franklin Roosevelt。结果 Roosevelt 赢得了48个州中的46个。问题在哪？杂志从电话簿和汽车登记名册抽样，过度代表了富裕选民。一个小而有代表性的样本，胜过一个大而有偏的样本。

**随机抽样**是黄金标准。它从概率上保证总体中每个成员都有相等的入选机会。这不保证样本一定具有代表性（运气不好时你可能抽到不寻常的样本），但它使样本在期望上无偏，并让你能量化可能的误差。

这里出现了与概率论的关键连接。当我们随机抽样时，样本统计量——均值、比例、方差——成为随机变量，遵循可以分析的概率分布。**抽样分布**是核心概念：想象你能从总体中抽取所有可能的样本，每个样本的均值会形成一个分布。中心极限定理告诉我们一个惊人事实：无论总体分布什么形状，样本均值的分布都会随样本量增大而趋近正态分布。

抽样分布的标准差称为**标准误**，对于样本均值是 $\sigma/\sqrt{n}$。注意这里的平方根：样本量翻倍不会使不确定性减半，只会减少约30%。要将不确定性减半，你需要四倍的数据量。这解释了为什么样本量在研究设计中如此重要——检测小效应需要大样本。

## 估计：最佳猜测与不确定性范围

如果你想知道总体均值，最直接的方法是计算样本均值并作为估计。这看似显而易见，但什么使一个估计好于另一个？

**点估计**给你一个最佳猜测的数值。样本均值 $\bar{x}$ 用于估计总体均值 $\mu$。好的估计量应该是**无偏的**（平均而言正确）、**有效的**（不同样本间变异小），并且**一致**（随样本量增大而改进）。

但点估计给人虚假的精确感。说总体均值是170厘米听起来很确切，却掩盖了不确定性。**置信区间**提供了一个合理值的范围。95%置信区间大约是：

$$\bar{x} \pm 1.96 \times \frac{s}{\sqrt{n}}$$

这里的 $s$ 是样本标准差，$n$ 是样本量。

**关键提示**：95%置信区间不意味着真实参数有95%的概率落在其中。真实参数是固定的（它要么在区间内，要么不在）；概率指的是这个程序。如果你从不同样本构造许多95%置信区间，约95%会包含真实参数。这种频率学派的解释让人不满意，因为我们通常关心的是具体的这个区间，而非假想的重复试验。

## 假设检验：证据的逻辑

假设检验问的是不同的问题："数据与某个假设是否一致，还是提供了反对它的证据？"

框架采用反证法。我们从**原假设** $H_0$ 出发，通常代表"无效应"。然后问：如果原假设为真，我们的数据会有多令人意外？

看一个例子：制药公司检验新药是否降低血压。100名患者随机分配——50人药物，50人安慰剂。药物组血压平均多下降8毫米汞柱。

原假设是药物无效——任何差异都只是随机变异。在原假设下，我们计算纯粹由随机因素观察到8毫米汞柱（或更极端）差异的概率。这就是**p值**。

如果p = 0.003，我们的数据在原假设下极不可能。我们面临选择：要么三百分之一的小概率事件碰巧发生，要么原假设错了。通常我们会拒绝原假设，得出药物有效的结论。

如果p = 0.30，数据与原假设相当吻合。我们"未能拒绝"原假设。注意措辞：我们并未证明原假设为真，只是缺乏反对证据。

P值要多小才拒绝？传统阈值是0.05，称为**显著性水平** $\alpha$。但这个阈值完全是约定俗成——0.05没有什么神奇之处。Ronald Fisher 最初只是将其作为方便的基准提出，然后就沿用至今。无数关于药物、政策和科学论断的决定，都取决于p值是0.049还是0.051。

这里存在两类错误的权衡。**第一类错误**是当原假设为真时错误拒绝它（假阳性），概率是 $\alpha$。**第二类错误**是未能拒绝实际为假的原假设（假阴性），概率是 $\beta$。检验的**统计功效**是 $1 - \beta$，即正确检测真实效应的概率。

适当的平衡取决于情境：药物试验中，假阳性意味着批准无用甚至有害的治疗，低第一类错误率至关重要。严重疾病筛查中，假阴性意味着漏诊，统计功效更重要。

## P值：最常被误解的概念

P值的真正定义是：**在原假设为真的前提下**，观察到与当前数据同样极端或更极端结果的概率。这是一个条件概率 P(数据至少这么极端 | 原假设为真)。

P值**不是**什么？

**不是原假设为真的概率。**p = 0.03不意味着治疗无效的概率是3%。原假设要么真要么假；p值描述的是数据，不是假设。要得到 P(原假设为真 | 数据)，需要贝叶斯方法和先验概率。

**不是效应大小或重要性的度量。**微小到毫无实际意义的效应，只要样本足够大，也能得到极小的p值。一项涉及数百万人的研究可能发现冥想使焦虑评分（100分制）降低0.1分（p < 0.001）——统计显著，但临床无意义。反过来，大而重要的效应，如果样本小，也可能p值较大。

**不是可重复性的指标。**p = 0.03不意味着该发现有97%概率能重复。即使真实效应，在不同重复实验中也常产生不同p值。原始研究中p = 0.03的真实效应，在相似规模的重复研究中完全可能得到p = 0.12。

那我们该关注什么？**效应量**衡量效应有多大，与样本量无关。Cohen's d 是标准化均值差；相关系数衡量线性关联强度；比值比衡量一组中某结果相对另一组的几率。

**例子**：新教学方法使测试成绩提高2分（d = 0.1），在10000名学生中p = 0.001。高度显著但微不足道。另一项仅30名学生的试点显示成绩提高15分（d = 0.75），p = 0.08——不显著，但效应量表明值得进行更大规模研究。

## 多重比较：当你检验20次

如果你在0.05水平检验一个假设，当原假设为真时，你有5%的假阳性概率。但如果你检验20个假设？即使所有原假设都为真，你也会预期约一个"显著"结果纯粹出于偶然——20 × 0.05 = 1个预期假阳性。

这种**多重比较问题**大幅推高假阳性率。研究者测量20个指标却只报告显著的那些，往往发现虚假效应。基因研究检验数百万个变异，仅凭偶然就会发现成千上万个"显著"关联。

**Bonferroni校正**将显著性水平除以检验次数。对于20次检验，每次使用 0.05/20 = 0.0025。简单但保守。**预注册**——在看到数据前明确假设和分析计划——防止研究者尝试多种分析后只报告显著的那些。

更深层的问题在于：假设检验是为事先明确单一问题设计的。许多现代研究涉及从数据中探索模式，需要不同的统计思维。

## 频率学派与贝叶斯：两种哲学

到目前为止讨论的都是**频率学派**方法。但还有另一种选择：**贝叶斯推断**。

频率学派将概率解释为长期频率。概率0.5意味着无限次重复中事件发生一半的次数。按这种解释，对固定未知量赋予概率没有意义。总体均值有一个真值，所以问"均值在165到175之间的概率是多少？"毫无意义。

贝叶斯学派将概率解释为信念程度。这允许对任何不确定事物赋予概率，包括固定参数。数据通过贝叶斯定理更新先验信念，产生后验分布。贝叶斯**可信区间**正是人们想要的：参数以指定概率落入的区间。

贝叶斯推断需要指定先验分布。这既是优势（纳入真正的先验知识），也是挑战（当先验知识匮乏时怎么办？）。批评者认为先验注入主观性。辩护者说先验使假设明确而非隐藏，而且证据足够强时，先验会被冲淡。

在实践中，两种方法在大样本和弱先验时往往给出相似答案。哲学差异对解释的影响大于对计算的影响。大多数统计学家务实地使用两种方法，根据问题选择，而非出于立场。

## 回归：建模关系

我们常想了解变量间的关系：血压如何随年龄变化？收入如何取决于教育？**回归分析**建立响应变量与预测变量间关系的模型。

**简单线性回归**：$Y = \beta_0 + \beta_1 X + \epsilon$。斜率 $\beta_1$ 告诉我们，$X$ 每变化一个单位，$Y$ 平均变化多少。

**多元回归**扩展到多个预测变量。每个系数代表**在控制其他变量情况下**的效应。这种"控制"对分离可能相互混淆的效应至关重要。

但回归系数不能轻易做因果解读。教育与收入间的关联可能反映因果关系，也可能反映反向因果、混杂因素或选择偏差。

警示案例：观察性数据一致显示激素替代疗法与较低心血管风险相关。基于此，医生广泛推荐HRT。然后妇女健康倡议——大型随机试验——发现相反结果：HRT实际*增加*心血管风险。观察性关联反映的是混杂：更健康、受教育程度更高的女性更可能接受HRT，因其他原因本身风险就低。

确立因果要么需要实验操控（随机对照试验），要么需要观察性数据的复杂方法，都有难以验证的假设。

## 统计陷阱：警惕误用

**P值操纵与研究者自由度**：检验多个指标只报告显著的，看到哪些亚组有效后再分析亚组，当结果显著时停止收集数据。这些做法往往无意识。研究者真心希望发现效应，无数小决定集体性地将结果偏向显著。

如果你有10个合理分析选择，每个2个选项，就是1024种可能分析。如果尝试几种并报告最显著的，实际假阳性率可能远高于5%。补救是**预注册**：收集数据前明确假设和分析计划。

**发表偏倚**：期刊偏爱阳性结果。设想100个实验室各研究一个实际无效的治疗，约5个会因偶然得到p < 0.05，可以发表。如果只有这5个发表，文献就会显示该治疗"有一致证据"支持。

**混淆显著性与重要性**：统计显著性高度依赖样本量。足够数据，微不足道的效应也会显著。200万份医院病历研究发现周末入院死亡率显著更高（p < 0.001），媒体宣称"周末入院更致命"。但实际差异只有0.08个百分点——效应极小，可被无数微小混杂解释，对多数患者无实际意义。

永远要问："效应有多大？"而不仅仅是"是否显著？"

## 可重复性危机

自2011年以来，心理学、医学、经济学等领域面临令人不安的发现：许多已发表结果无法重复。

开放科学合作组织尝试重复顶级期刊发表的100项心理学研究。只有36%在相同方向显示出显著效应。平均效应量只有原始报告的一半。

多种因素导致这一问题：发表偏倚、p值操纵、统计功效不足、将p < 0.05视为定论、发表新颖发现的压力、对重复研究激励不足。

应对措施包括：预注册、注册报告（数据收集前评审）、公开数据和代码、扩大样本量、多中心重复项目、期刊政策改革。进展真实但缓慢。学术激励结构仍偏重新颖性而非可靠性。

## 关联

本主题建立在**概率论（主题32）**的数学基础上，为抽样分布、假设检验和贝叶斯推断提供理论。**贝叶斯推理（主题34）**发展了统计推断的另一种框架。这里的不确定性量化与**信息论（主题35）**相关联，后者用熵衡量信息含量。统计方法是整个课程中经验方法的基础。

## 延伸阅读

**基础入门**
- David Freedman 等著《Statistics》（第4版）。理解统计思维的最佳入门，强调概念而非公式。

**通俗实用**
- Alex Reinhart 著《Statistics Done Wrong》。关于研究中常见统计错误的优秀指南，批判性评估已发表研究的必读。
- David Spiegelhalter 著《The Art of Statistics》。深思熟虑、通俗易懂，强调关于不确定性的推理。

**因果推断**
- Scott Cunningham 著《Causal Inference: The Mixtape》。从观察性数据进行因果推断的计量经济学方法。
- Judea Pearl 和 Dana Mackenzie 著《The Book of Why》。因果图和因果数学的可读性入门。

**可重复性危机**
- Stuart Ritchie 著《Science Fictions》。对科学实践如何产生不可靠结果及应对措施的全面阐述。

---

*关联：本主题建立在概率论（主题32）的数学基础和概率与统计思维（主题4）的概念框架之上。这里介绍的贝叶斯方法在贝叶斯推理（主题34）中得到全面发展。不确定性和信息的量化与信息论（主题35）相关联。*

---
topic_id: 33
part: II
section: "概率与统计"
difficulty: 7/10
estimated_reading_time: 25 minutes
prerequisites: [4, 32]
related_topics: [34, 35]
core_concepts: ['估计', '置信区间', '假设检验', 'p值', '效应量', '可重复性危机']
---
