# 认知偏误
*人类推理中的系统性错误*

想象一位经验丰富的医生正在诊断病人。她看到症状，脑中闪过一个判断——这很可能是某种疾病。接下来发生的事情很微妙:当检查结果指向另一个方向时,她发现自己在重新解读数据,试图让它符合最初的直觉。矛盾的证据?被自然而然地淡化了。她聪明、专业、真心想帮助病人,但她的推理过程在她意识不到的情况下出了问题。

或者想想你自己。当你已经相信某件事——某个政客不可信、某项技术很危险、某个朋友值得依赖——世界似乎总是不断提供证据来证实你的看法。这是因为你判断对了,还是因为别的什么在起作用?

这些都是**认知偏误**的表现——系统性的判断偏差。它们不是因为你笨或者不够小心,而是源于人类大脑的基本工作方式。理解这些偏误,是每个想要清醒认识世界的人必备的装备。

## 为什么聪明人也会犯可预见的错误

在认知偏误研究兴起之前,判断失误通常被归因于三种原因:不了解事实、思考不够审慎,或者想相信自己愿意相信的东西。心理学家 Daniel Kahneman 和 Amos Tversky 在 1970 年代的研究彻底改变了这个认识。

他们发现:即使是聪明、审慎、出于善意的人,也会犯下**可预测的**错误。相同的错误会在不同的人、文化、情境中反复出现。偏误不只是个人的失误,而是像我们这样的心智倾向于犯的错误。

核心原因在于,人类的认知依赖**心理捷径**——即启发式方法(heuristics)。这些方法在大多数情况下运转良好,但在某些特定情境下会可预见地失效。

想想 Kahneman 后来提出的著名概念:**系统1与系统2思维**。

系统1自动、快速、不费力气。当你认出一张面孔、理解一句话、看到恶心的画面感到厌恶,那就是系统1在工作。

系统2负责需要注意力的心智活动——复杂计算、深思熟虑的推理、需要集中精力的选择。

关键在于:**我们大部分时候靠系统1运作**。我们通过快速模式匹配、情绪反应、直觉判断来应对世界。系统2很"懒"——启动它需要努力,消耗心智资源。多数时候,系统2只是简单地认可系统1产生的印象和直觉,将它们转化为信念和行动,却不加批判性审视。

认知偏误,在很大程度上就是系统1思维的典型错误。

## 演化的遗产

这些偏误为什么存在?从演化角度看,令人困惑的不是我们有偏误,而是我们怎会期待没有偏误。

想想我们祖先面临的决策:草丛中的动静是捕食者还是风?陌生人是敌是友?这食物能吃吗?在这样的环境中:

**速度比准确性更重要。** 多花几秒钟判断草丛里是不是狮子,延误的代价可能是死亡。自然选择青睐快速而粗略的判断,而非缓慢精确的分析。

**误报好过漏报。** 把石头错认成狮子而逃跑,不过浪费点体力;把狮子错认成石头,就意味着死亡。这种不对称性塑造了我们的威胁检测系统——宁可信其有。就像烟雾报警器:偶尔误报总比漏报真火要好。

**信息有限且局限于本地。** 我们的祖先没有统计数据库、科学研究或全球新闻。他们只能依据亲身经历和身边人的讲述做决策。基于有限本地样本就能运作的启发式方法,比需要大规模数据的方法更受青睐。

**社会声誉至关重要。** 人类高度依赖群体合作。帮助我们处理社会关系的认知机制——识别欺骗、维护联盟、建立声誉——承受着强烈的选择压力,即使它们有时会妨碍纯粹的认知目标。

这些演化压力解释了为什么许多偏误具有这样的特性。它们不是软件漏洞,而是在我们认知架构演化的环境中合理的功能特性。

问题在于:**我们在用石器时代的心智应对信息时代的世界。**

这不意味着我们应该接受偏误。理解其根源有助于识别它们,但目标仍然是正确认识世界本来的样子。

## 最重要的几种偏误

研究者已识别出数十种认知偏误。与其穷尽列举,不如深入理解几种最核心、影响最广的。

### 可得性启发式:容易想到≠常见

我们根据例子浮现脑海的难易程度来判断事件的概率。能快速想到某事的例子,就会隐含地认为它很常见。

这通常是有效的——频繁发生的事确实更容易被记住。但它会被那些影响记忆难易而非实际频率的因素系统性扭曲。

戏剧性事件(空难、恐怖袭击)比寻常事件(车祸、心脏病)更容易被记住,导致我们高估其频率。近期事件比久远事件更易想起。亲身经历比统计数据更突出。

结果就是一幅扭曲的风险地图:**我们害怕生动鲜明的威胁,却忽略真正危险的事物。**

对比一下:美国每年约38,000人死于车祸,约600人死于航空事故。但许多人对飞行焦虑,对开车却习以为常。差异不在实际危险,而在戏剧性空难报道的可得性。

媒体报道放大了这一效应。新闻大量报道某类犯罪时,人们感知到更多危险,即使犯罪率实际在下降。感知风险与实际风险的关系,开始受注意力经济而非统计现实的调节。

### 确认偏误:寻找你想看到的

这可能是所有偏误中最普遍、最有害的一种。我们倾向于以证实已有信念的方式去寻找、注意、解读和记忆信息。

它在多个层面运作:

**选择性接触。** 我们选择与自己观点一致的信息源。自由派看自由派媒体,保守派看保守派媒体。社交媒体上加的好友都是观点相近的人。

**选择性注意。** 遇到混合证据时,我们注意并记住支持自己立场的部分,忽略矛盾信息。

**选择性解读。** 模糊证据会被解读为支持已有信念。同一项研究,一方视为确凿证据,另一方视为方法有缺陷——尽管看的是同样的东西。

**选择性记忆。** 随时间推移,我们对证实信念的信息记忆更深刻。

有个惊人实验:参与者被展示关于死刑威慑效果的虚构证据。支持和反对死刑的双方都认为支持自己立场的研究方法更严谨——即使两项研究方法完全相同,只是结论不同。看完同样的混合证据后,双方原有信念都得到了强化。

确认偏误解释了为什么聪明、信息充分的人看着同样的证据却得出截然相反的结论。这不是某一方愚蠢,而是双方都通过先入之见塑造的滤镜处理信息。

这种偏误尤其阴险,因为它感觉像真正的探究。你确实在寻找和评估证据——只是以一种系统性偏颇的方式,强化而非挑战已有观点。

### 锚定效应:第一印象的力量

初始信息对后续判断产生过度影响。

著名实验:受试者被问甘地是在9岁之前还是之后去世(或140岁之前还是之后)。回答第一个问题的人随后估计的死亡年龄较低,回答第二个问题的人估计较高——尽管两个锚点都荒谬。

锚定影响谈判(第一个报价设定范围)、定价(标价影响支付意愿)、法律判决(检察官的量刑建议影响判决)。机制似乎是从锚点出发调整不足——我们从给定数字开始调整,但调整幅度不够。

房地产交易中,挂牌价锚定买家预期,即使他们知道价格可能虚高。同一条街的相同房子,要价相差10%,买家出价通常追随这些任意差异。即使专业经纪人也表现出这种效应。

### 基础比率谬误:忽视大背景

我们倾向于忽视相关统计信息,偏好具体个案细节。

经典问题:1%的女性患乳腺癌。检查正确识别癌症的概率90%,假阳性率9%。一名女性检测呈阳性,她患癌概率是多少?

大多数人(包括许多医生)猜80-90%。正确答案约9%。

为什么?想象1,000名女性。10人患癌(1%),检测识别出9人。990名未患癌女性中,约89人假阳性(9%)。因此98个阳性结果中,只9个真阳性。

基础比率——只有1%患癌——至关重要,但往往被忽视。我们被故事、个案、具体细节吸引,却忘了本应指导判断的统计背景。

### 过度自信:我们不知道自己不知道

这是判断心理学中最稳健的发现之一。在各个领域,人们对判断的信心都大大超过实际准确性。

人们声称90%信心时,实际只70-80%正确。要求给出应有90%概率包含正确答案的范围时,他们给的范围实际只约50%概率包含。估计项目时长时,系统性低估——这种现象有专门名称:**规划谬误**。

大型基础设施项目平均成本超支50%以上。新企业五年内约50%倒闭。然而每个新项目、新企业开始时都伴随自信满满的预测。

有趣的是,过度自信与实际能力的关系反直觉。能力最差的人往往最过度自信,专家更加校准但仍过度自信。这被称为**邓宁-克鲁格效应**:无能剥夺了人们识别自己无能的能力。做出正确判断的技能,恰恰是识别判断是否正确的技能。

### 沉没成本谬误:已经投入的就是失去的

我们在决定是否继续时,会考虑过去已无法收回的投入。从理性角度,只有未来成本和收益应该被考虑——已花掉的就是花掉了。但心理上,我们不愿"浪费"已投入的东西。

这解释了为什么人们坐在电影院看完不喜欢的电影(已买票),公司继续投入失败项目(已投那么多),国家继续打注定失败的战争(已牺牲的士兵),人们留在糟糕关系中(已投入的岁月)。

沉没成本谬误部分源于**损失厌恶**——我们更在意损失而非等量收益。放弃意味着确认损失,继续还有扭转希望。也关乎自我辩护:承认过去投入白费,就是承认自己犯错。

### 后见之明偏误:过去看起来总是可预见的

我们倾向于认为过去事件是可预见的,即使实际并非如此。事情发生后,我们很快构建出让它看起来不可避免的解释。

房地产市场当然会崩盘——有那么多预警信号。那家创业公司当然会成功——创始人那么有才华。

这种偏误有害,因为它扭曲了我们从经验学习的方式。事后看来事件似乎可预见,我们就不会充分反思未能预见的失败。我们认识不到预见能力的局限,因为错误地记忆了过去的预测。

2008年金融危机:事后,预警信号似乎显而易见——次级贷款、过度杠杆、复杂衍生品。但事前,绝大多数经济学家、监管者、市场参与者都没预见到。后见之明偏误让我们谴责他们未能预测那些事后看来不可避免的事。

后见之明偏误还滋生过度自信。因为过去看起来可预测,我们假定未来也是。我们没充分认识到偶然性的作用、预测的困难、模型的局限。

## 我们能克服偏误吗?

这是至关重要的问题。诚实的回答是:**可以部分克服,但需要付出努力。**

挑战是根本性的。你无法跳出自己的认知来检查它是否正常工作。你用来检测和纠正偏误的能力,恰恰是产生偏误的能力。某种意义上,偏误对自身是隐形的。

更重要的是,**仅仅了解偏误不能让你免疫。** 研究一致表明,学习认知偏误的知识对减少其影响效果甚微。你可以知道沉没成本谬误,却仍然看完烂片。你可以知道确认偏误,却仍然选择性寻找支持观点的信息。智识知识不会自动转化为判断力提升。

这似乎令人绝望,但情况并非毫无希望。

### 有效的去偏误策略

**考虑相反面。** 最有效的去偏误策略之一。评估假设时,主动生成它可能错误的理由。做决定时,阐述支持另一选项的论据。这通过迫使我们关注反面证据,直接对抗确认偏误。

关键是认真对待——不是走过场,而是真正投入地与反方立场交锋。问自己:"如果我的信念错了,我应该看到什么?我有去寻找那样的证据吗?"

**事前验尸分析。** 在实施计划前,想象它已彻底失败。现在解释为什么。这能揭示乐观偏误可能掩盖的风险和潜在问题。想象失败原因比批评已投入的计划要容易得多。

**参照类预测。** 对抗规划中的过度自信。不要通过分析项目具体特征估计时间表(内部视角),而是看类似过往项目实际花了多长时间(外部视角)。这通常产生更现实估计。

规划家庭装修时,不要根据你的项目会怎样来估计,而是了解类似装修实际花了多长时间。外部视角几乎总给出更长估计,而外部视角几乎总更准确。

**放慢速度。** 给系统2一个机会捕捉系统1的错误。许多偏误源于快速直觉加工。做重要判断前简单停顿——睡一觉,等一天——可以通过允许深思熟虑反思来减少偏误。

**让隐形的变可见。** 事件发生前写下预测,然后与结果比较。记录决策日志,注明做了什么决定、为什么、预测会发生什么。这些记录使后见之明偏误和自利性记忆更难维持。

### 设计更好的环境

个人去偏误有局限。更有力的方法是**设计能补偿可预测偏误的环境和流程。**

**结构化决策。** 清单确保相关信息不被忽略。评估前确立明确标准,防止事后合理化。强制考虑替代方案,对抗现状偏误和确认偏误。

**多元视角。** 不同人有不同偏误。群体讨论可以揭示个人遗漏的考量——尽管也可能通过群体思维放大共有偏误。结构化分歧、"魔鬼代言人"、红队可以将多元性转化为偏误纠正的力量。

**反馈机制。** 许多偏误持续存在,因为我们得不到清晰反馈。天气预报员和职业赌徒校准度好,因为得到快速明确的预测反馈。设计能提供这种反馈的系统——并使之无法逃避——可以随时间改善判断力。

**默认设置与选择架构。** 利用偏误做好事。如果现状偏误强大,就把更好选项设为默认。如果框架重要,就用能突出重点的方式呈现选择。这是"助推"(nudge)干预的领域——利用行为科学洞见设计引导更好决策的环境,不限制选择自由。

将器官捐献设为默认(退出机制)的国家,捐献率85-99%;需主动选择加入的国家只4-27%。差异不在价值观,在默认设置如何与现状偏误互动。

### 现实的期待

我们应该诚实面对什么是可实现的。完全去偏误既不可能,也不一定可取。我们的启发式方法在许多情境下运作良好,追求完美校准的推理所需努力令人望而却步。

目标不是成为纯粹理性的智能体,而是**识别偏误何时可能在重要决策上误导我们,并为这些情况准备好工具。**

还有社会维度。去偏误往往需要他人帮助——挑战我们思维、提供不同视角、督促我们负责的人。身处重视准确推理、奖励根据证据更新观点、不惩罚承认不确定性的社群,比任何个人技术都更有帮助。

最后,动机很重要。去偏误需要努力,我们只有真正在乎相信真实的事物、做出好决定时,才会持续付出这种努力。在许多情境下,人们有其他目标——看起来好、融入群体、感觉舒适——这些与认知准确性竞争。

**真正想要正确,可能是克服偏误最深层的要求。**

## 为什么这很重要

理解认知偏误在各个领域都重要:

**个人决策。** 对偏误的认识可以改善人生重大抉择——职业、关系、财务。认识沉没成本思维可能帮你离开失败关系。承认过度自信可能促使你多储蓄或寻求第二意见。理解框架效应让你不那么容易被营销操纵。

**专业领域。** 许多行业已开始系统性应对偏误。医学界使用清单和结构化流程。情报分析采用结构化技术克服确认偏误。法律系统用盲审程序减少证据评估偏误。金融界认识到行为偏误在投资决策中的普遍性。

**理解社会问题。** 偏误研究阐明了从政治极化(确认偏误如何创造信息茧房)到歧视(内隐偏误如何塑造行为),再到错误信念为何持续存在(动机性推理如何保护珍视观点)等现象。

**长期思维。** 范围不敏感性和时间贴现结合,使我们系统性低估未来。我们对即时、生动威胁情绪反应,却忽视缓慢发展的灾难和遥远可能性。这对我们如何应对生存风险、气候变化和其他跨越数十年乃至数百年的挑战有深远影响。我们的认知架构使我们难以认真对待超出直接视野的事物。

**智识谦逊。** 也许最根本的是,研究认知偏误培养了对自身推理能力的适度谦逊。我们不是常常自以为的那种透明、理性的推理者。我们的信念和判断被我们看不见、无法完全控制的力量塑造。

这一认识不会损害对真理的追求——它让这种追求变得更现实。

## 不同的观点

认知偏误研究影响深远,但也面临值得认真对待的批评。

**生态理性观点** 认为,那些看起来像偏误的东西,实际上是对正常环境的良好适应,只在人为实验室情境中失效。可得性等启发式方法并非统计推理的有缺陷近似,而是在人类认知演化环境中真正有效的策略。

**可重复性问题** 提醒我们保持谦逊。心理学正面临可重复性危机——许多研究发现未能被重复验证。核心发现如锚定、确认偏误、过度自信已被稳健重复,但某些特定偏误可能被夸大或更依赖特定情境。

**社会功能观点** 提出,人类推理能力主要为社会论辩而非个人求真而演化。确认偏误不是漏洞而是功能:在不同人为不同立场辩护的社会情境中,让每个人强力支持自己观点,可能比让每个人完美平衡更能使群体得出更好结论。

这些观点不是否定偏误研究,而是提醒我们理解其边界和复杂性。

## 延伸阅读

**Kahneman, Daniel.《思考,快与慢》(2011)。** 该领域创始人撰写的权威通俗著作。全面、易读,对人类判断机制有深刻洞见。想了解自己心智的人必读。

**Thaler, Richard, and Cass Sunstein.《助推》(2008)。** 将行为洞见应用于政策和制度设计,展示如何在不限制自由的情况下通过理解偏误获得更好结果。偏误研究的实际应用。

**Mercier, Hugo, and Dan Sperber.《理性之谜》(2017)。** 具挑战性的另类视角,认为推理主要为社会论辩而非求真而演化,这解释了它如何运作及为何失效的许多特征。

---

*关联:本主题建立在《证据与推理》(理解什么是好证据)的基础上,并应用了《批判性思维》(评估论证和避免谬误)中的原则。它为《决策理论》(揭示为什么直觉决策系统性地偏离理性理想)提供重要基础,并阐明了为什么长期思维的进步需要克服我们天生的短视和范围不敏感性(参见《长期未来》)。*
