# 预测与预见
*关于未来,我们能知道什么,不能知道什么*

考虑两个问题:明天伦敦的气温是多少?未来十年台湾会爆发战争吗?

两个问题都在追问未来,但我们应对它们的方式有天壤之别。第一个问题有明确答案,气象学可以将误差控制在几度之内。第二个问题涉及人类决策、地缘博弈,以及以不可预测的方式层层递进的偶发事件。

但这不意味着第二个问题毫无意义。有些人在这类问题上的预测始终比其他人更准确。研究发现,预测是一种可以习得的技能,有系统方法可循——前提是我们理解什么让不同现象更容易或更难预测,并且愿意追踪自己的准确率,从错误中学习。

我们之所以预测,是因为必须在未来到来之前采取行动。每个决策——选择职业、是否买房、投资什么——都隐含着对后果的预测。越理解什么可以预测、如何预测,就越能在不确定的世界中找到方向。

## 预测的起点:基准率

实践预测中最重要的概念或许是**基准率**(base rate):某事在相关群体中发生的频率。在问*这家*创业公司是否会成功之前,先问问创业公司总体上有多少成功的。在预测*这段*关系是否会持久之前,考虑一下类似情侣的离婚率。

这些数字往往令人警醒。大约90%的创业公司会失败。美国约40%到50%的初婚以离婚告终。60%的餐厅在第一年关门,80%撑不过五年。大多数已完成的并购交易会摧毁股东价值。

基准率提供了锚点,保护我们免于过度自信。开餐厅的人通常会把注意力集中在成功的所有理由上——创新菜单、完美地段、敬业团队。他们很少将这些与80%失败率这一冷酷事实放在天平上衡量。

这不是悲观主义,而是校准。基准率告诉你在纳入具体信息之前应该期待什么。有时确实有理由偏离基准率——一家由资深餐饮老手经营、资本充足、在供给不足市场验证过商业模式的餐厅,预测应该与资金紧张的新手不同。但偏离程度应与证据强度成正比。

**计划谬误**说明了忽视基准率会发生什么。心理学家Daniel Kahneman发现:人们总是低估项目需要多长时间、花费多少成本,即使有相关经验。悉尼歌剧院预计4年完工,实际用了16年;预算700万美元,最终花了1.02亿。这不只是政府项目的问题——研究显示只有约三分之一的软件项目能按时按预算完成,家庭装修平均成本超支30%到50%。

这种模式之所以顽固,是因为人们关注自己项目的具体特征,而不是类似项目实际进展的基准率。

### 参照类的难题

基准率的力量伴随着一个难题:如何选择正确的参照类。

预测一个新社交网络是否会成功,参照类是"所有创业公司"(90%失败)?"科技创业公司"?"社交网络"?"由经验丰富企业家在2020年代创立、资金充足的社交网络"?每个给出的基准率都不同。

没有纯粹客观的答案。正确的参照类取决于你认为哪些特征与结果有因果关联。一些指导原则:

**根据因果相关性选择,而非表面相似性**。悉尼歌剧院和你的厨房装修都是"建筑项目",但复杂程度、新颖性、利益相关者数量等结构性特征更重要。

**较大参照类提供更多统计稳定性**。来自1000个案例的基准率比20个更可靠。但如果较大类别包含在因果上重要方面存在差异的案例,这种精确性就是虚幻的。

**警惕缩小参照类以获得有利基准率的倾向**。"像我这样的餐厅有80%成功"往往意味着"我把参照类定义得只包括成功案例"。

## 内部视角与外部视角

基准率与具体推理之间的区分,映射到一个更广泛的框架:**内部视角**与**外部视角**。

**内部视角**审视情境的具体特征。预测项目需要多长时间时,你会考虑需要完成的具体任务、每项任务应该花多长时间、可能出什么问题。你从内部建构预测,构想事情将如何展开。

**外部视角**则问:"在看起来像这样的情况下,发生了什么?"你忽略具体细节,看分布模式。类似项目实际花了多长时间,不管人们当初预测的是什么?

两种视角都捕捉了真实信息。内部视角反映真实知识——有些项目确实更简单,有些团队确实更有能力。忽视这些信息意味着忽视了使这个案例与众不同的因素。

但内部视角以可预测的方式系统性失败:

- 我们低估可能出错的事情(乐观偏见)
- 我们关注看得见的,忽视看不见的
- 我们构建让成功看起来板上钉钉的叙事
- 我们把感觉自信误认为有好的理由
- 我们制定假设一切按计划进行的计划

外部视角通过将预测建立在实际结果上来纠正这些偏见。当你看到数据显示90%的类似项目都延期完工时,就很难对自己的项目按时完成过度自信了。

### 整合两种视角

解决方案不是为了外部视角而放弃内部视角,而是从外部视角开始,审慎地调整。

Kahneman和Amos Tversky推荐的程序:

1. 确定相关参照类
2. 确定该类别的基准率
3. 确定是什么使你的案例与众不同
4. 估计这些差异应该使预测偏移多少
5. 检查你的调整相对于参照类中的典型变异是否过大

第4步是判断介入的地方。你的团队以前成功合作过,应该使完成时间估计偏移多少?没有公式。但从基准率开始迫使你明确地为调整提供理由,而不是构建一个不受分布现实约束的估计。

考虑一位风险投资家评估一家自动配送机器人创业公司。创始团队来自Google和MIT,筹集了5000万美元,初步试点显示有希望的结果。

内部视角关注这些细节:精英技术专长、强大投资者支持、早期结果表明技术可行、市场快速增长、CEO曾成功出售前一家公司。这种分析可能得出60%到70%的重大成功概率。

外部视角问的是不同问题:B轮机器人创业公司中有多少比例达到重大退出?(也许5%到10%)有精英创始人和顶级投资者支持的创业公司呢?(也许15%到20%)

外部视角指向大约10%到20%的概率。内部视角的因素是真实的,但它们恰恰是导致以前的投资者资助以前失败的机器人公司的因素。每家失败的创业公司都有一个让成功看起来很可能的故事。强大团队和资金应该使估计从基准率向上调整,但也许调整到25%到30%——而不是60%到70%。

## 什么可以预测,什么不可以

### 为什么未来竟然是可知的

我们能够预测任何事情,这本身就令人惊叹。宇宙本可以是一片混沌,让预测完全不可能。然而我们发现了规律性。太阳照常升起,季节循环往复,物体落地时总是下落。原因产生可靠的结果。

这种规律性源于因果结构。两类知识支撑着预测:

**机制性理解**通过模拟因果关系来实现预测。如果我们了解轨道力学,就能计算出火星在一千年后的位置。1977年发射的旅行者号航天器,利用提前数十年预测的引力弹弓效应在行星之间穿行。牛顿方程结合精确测量,可以对受充分理解的物理定律支配的系统作出极其准确的预测。

**统计模式**即使在没有机制性理解的情况下也能实现预测。保险公司预测事故率,却不知道哪些具体司机会出事。死亡率表预测大约0.1%的40岁美国人会在一年内死亡,却不能确定是哪些个体。当过去的模式延续到未来时,这种方法就能奏效。

两种方法都有局限。在太多原因相互作用的复杂系统中,机制性理解会失效。当底层系统发生变化时,统计模式也会失灵。

### 为什么未来抗拒认知

几个特征使未来具有根本性不确定性:

**偶然性**:许多结果取决于本可能轻易走向另一方向的特定事件。1914年6月28日,如果弗朗茨·斐迪南大公的司机没有在萨拉热窝走错路,刺客就不会有机会下手,第一次世界大战可能不会在那一年爆发。2000年美国总统大选取决于佛罗里达州的537张选票——如果几百人投票时选择不同,这个国家在21世纪头十年的轨迹将会大相径庭。

**反身性**:在社会系统中,预测可以改变它所预测的结果。预测一家银行会倒闭,可能引发挤兑,从而真的使其倒闭——2023年硅谷银行正是如此,储户一天内提走了420亿美元。George Soros凭借对金融市场反身性的理解积累了财富:价格不仅反映基本面,还会塑造改变基本面的行为。

**复杂性**:在拥有众多相互作用组件的系统中,结果以抵抗预测的方式从相互作用中涌现。完美理解水分子并不能告诉你风暴会在哪里形成。理解单个交易者的心理并不能告诉你股价会走向何方。相互作用产生了无法从部分推导出来的涌现属性。

**真正的新事物**:有些未来事件没有先例。1945年之前核武器并不存在,2007年之前没有人握过iPhone。预测真正新颖的现象需要想象力,而不仅仅是外推——即便是富有想象力的预测者也经常错过真正出现的东西。1995年,《新闻周刊》的计算机网络专家Clifford Stoll断言:互联网永远不会取代日报,也无法实现大规模电子商务。

**人的能动性**:与粒子或行星不同,人会做出选择。这些选择不是随机的——它们对理由、激励和环境做出反应——但它们引入的不确定性,与物理的不确定性有本质区别。

### 混沌:对初始条件的敏感依赖

20世纪60年代,气象学家Edward Lorenz在运行天气模拟时将初始条件略微四舍五入——从六位小数到三位,变化约为0.0001。他预期结果几乎相同。然而,模拟在几周内就完全分道扬镳了。起始条件的微小差异导致了完全不同的天气模式。

这就是**对初始条件的敏感依赖**,通俗地称为蝴蝶效应。在具有这种属性的系统中,小的不确定性随时间呈指数增长。由于我们永远无法以完美精度测量初始条件,我们的预测能力以由系统动力学决定的速率衰减。

天气清楚说明了这一点。现代天气预报能相当准确地预测明天的天气。五天预报稳步改进但仍不完美。两周左右是有效技能的极限——超过这个期限,天气预报几乎不比气候平均值更准。这不是气象学的失败,而是由大气动力学的混沌性质施加的根本限制。

重要的是:混沌不等于随机。混沌系统是确定性的——给定精确的初始条件,结果严格遵循。但实际的不可预测性产生于我们永远无法精确知道初始条件,而小误差呈指数放大。

混沌限制预测时域,但它并不使预测变得不可能或无用。混沌限制的是精确预测,而非所有预测。我们无法精确预测三周后某个特定飓风会在哪里登陆,但我们可以预测飓风季节会给某些地区带来飓风。而且随着风暴临近,我们可以预测越来越精确的路径——五天飓风路径预报在过去30年平均误差从约350英里降到了不到150英里。

不同变量有不同的可预测性。在气候系统中,具体天气是混沌的,但整体气候模式更稳定。我们无法预测明年某一天是否会下雨,但我们可以预测全球平均气温会比一个世纪前更高。天气(混沌的、短期的)与气候(统计模式、长期的)之间的区分是根本性的。

## 评估预测

### 什么是好的预测

预测不只是关于会发生什么的声明,而是一个附带概率的声明。"明天会下雨"可能意味着10%到99%的概率。好的预测使其概率明确。

评估预测需要评估概率,而不仅仅是事件是否发生。如果我说有20%的概率下雨,然后下雨了,我不一定是错的——20%概率的事件大约20%的时间会发生。如果我说有99%的概率然后下雨了,我也不一定是对的——我可能系统性地过度自信。重要的是我的概率是否与长期频率相匹配。

**校准**衡量预测概率与实际频率的匹配程度。如果我对一组事件预测30%的概率,其中30%发生了,我就校准良好。如果只有10%发生,我就是过度自信。完美校准意味着当你说"70%"时,事情发生的频率就是70%。

**分辨力**衡量预测在多大程度上区分了不同事件。对所有事情都预测50%,如果事件发生频率正好是一半,会产生完美校准——但这毫无用处。好的预测者在适当时做出高置信度预测,区分某事非常可能的情况和不太可能的情况。

关键是,评估预测需要多个预测。单个预测无法有意义地评估——即使我预测99%而事件没有发生,这也有1%的时间会发生。只有跨多个预测的模式才能揭示预测者的质量。

### 常见的失败模式

**过度自信**:以超出证据所能支持的确定性进行预测。这无处不在。当人们表达90%的信心时,他们通常只有大约70%到80%的时间是对的。感受到的确定性与实际准确性之间的差距大且持久。

**忽视基准率**:过于受案例特定信息左右,忽视分布模式。即使知道基准率的专家在推理具体案例时也经常无法适当地权衡它们。

**忽视未知的未知**:"可能出什么问题?"产生一个清单,但"可能出什么我们没想到的问题?"没有答案——然而这类事情经常发生。2008年金融危机、新冠疫情、以及大型语言模型的快速发展,都没有被大多数预测者充分预见。

**后见之明偏见**:事件发生后,把它们当作本来可以预测的。"我早就知道"通常是假的,但感觉是真的。这扭曲了学习——如果我们错误地记住自己过去的预测比实际更准确,我们就无法识别哪里出了问题并改进。

### 专家的问题

专家预测往往令人失望。政治学家Philip Tetlock具有里程碑意义的20年研究发现,政治领域的专家预测者几乎没有战胜简单算法,他们的信心与准确性几乎没有关系。拥有最令人印象深刻的资历和媒体曝光度的专家表现并没有更好——有时更差。

为什么专家可能在预测上失败?

**领域知识不等于预测技能**。理解事情为什么发生不一定有助于预测会发生什么。历史学家深刻理解第一次世界大战,但无法预测它的爆发。经济学家在事后理解衰退,但很少提前预测。

**激励与准确性背离**。专家因自信、令人难忘的声明和有趣的观点而获得奖励——而不是校准。说"我不知道"或"大概五五开"不会带来演讲邀请或媒体关注。

**意识形态透镜扭曲预测**。关于世界应该如何运作的强烈观点污染了关于它将如何运作的预测。Tetlock发现,意识形态观点更极端的专家预测记录更差。

这并不意味着专业知识对预测毫无价值——而是意味着过去的准确性是未来准确性的最佳预测指标。

## 如何改进

### 超级预测者

Tetlock通过预测锦标赛识别出了**超级预测者**——持续地胜过其他人的预测者,甚至击败了能获取机密信息的情报分析师。

超级预测者不一定是领域专家。他们来自不同背景。他们共同拥有的是思维方式:

**概率思维**:超级预测者用具体的概率思考,而不是模糊的语言。"可能"可以意味着55%到95%的任何东西。超级预测者说"65%"并且言必有据。

**频繁更新**:他们随着新信息到来而修订预测,往往是小幅度的。不是捍卫最初立场,而是持续纳入证据。"我上周是40%;这条消息使我调整到45%。"

**分解**:他们将复杂问题分解为子问题。"俄罗斯会在12月前入侵乌克兰吗?"变成:俄罗斯军事能力暗示什么?普京的过往记录对他的风险偏好暗示什么?西方的反应可能如何影响计算?预测子问题并组合它们约束了思考。

**主动寻求不同视角**:他们寻求反对意见。在确定预测之前,会问:不同意我的人会怎么说?反对我当前估计的最有力论据是什么?

**基准率锚定**:他们从参照类开始,然后从那里调整。

**对预测的成长心态**:他们将预测视为可学习的技能,并积极努力改进。他们保留记录,审查准确性,并试图理解自己的错误。

### 实用技术

**保留记录**。写下带有概率和日期的预测。大多数人错误地记住自己的预测比实际更准确。记录防止这种自欺,并使学习成为可能。定期对照结果审查你的预测。

**用具体概率思考**。将模糊的感觉转换为数字。"这可能行不通"变成"30%的成功机会"。这个数字最初可能是错的,但可以通过反馈改进。模糊则不能。

**生成多个参照类**。在做出判断之前,考虑:这种情况的基准率是多少?寻找多个有效的参照类,并注意它们何时分歧。

**进行事前验尸分析**。在开始项目或做出预测之前,想象它已经失败了。然后倒推:出了什么问题?这种技术由心理学家Gary Klein开发,能发现乐观规划所忽视的风险。

**考虑相反的情况**。当你倾向于某个预测时,问:什么会使相反的情况发生?如果我错了,我预期会看到什么证据?这抵消确认偏见。

**增量更新**。当新信息到来时,审慎地调整概率。问:这个证据应该使我的估计改变多少,向哪个方向?避免要么忽视新信息要么对它过度反应的诱惑。

## 应用

### 个人决策

**对于重大人生决策**(职业、关系、重大购买),寻找基准率。像你这样的人的婚姻持续多久?在你这个年龄进入你选择的职业的人,结果分布如何?这不是宿命论——而是校准。你的具体情况很重要,但它们作为对基准率的调整而重要,而不是取代它们。

**对于规划**,系统地增加缓冲。计划谬误在各种情境中都很顽固。如果你的估计说一个项目需要三个月,而类似项目通常超支50%,那就规划四个半月。设定预算时预期超支。留出余地。

**对于在不确定性下评估选项**,考虑情景范围而不是单一估计。如果事情进展顺利会怎样?合理情况?糟糕情况?在多个情景中都稳健的决策优于需要特定预测才能实现的决策。

### 商业与战略

**市场预测**出了名地困难。解决方案:专注于你能知道的(你的能力、你的成本、你的执行力)而不是本质上不可预测的(精确的市场时机)。稳健战略——在一系列市场情景中都能合理运作的战略——胜过为单一预测的未来优化的战略。

**项目预测**应该锚定在类似过去项目的参照类上。实施正式参照类预测的组织——看类似项目实际表现如何而不是自下而上构建估计——在准确性上看到了显著改进。英国政府自2004年以来要求对重大项目进行参照类预测,这种方法将乐观偏见减少30%到50%。

### 政策与治理

**要求明确的概率预测**。模糊的预测("可能"、"也许")无法被评估或从中学习。强制具体化。美国国家情报委员会现在在关键判断中包含概率范围正是出于这个原因。

**为不确定性而设计**。在一系列预测范围内都能运作的政策优于需要特定预测才能实现的政策。内置反馈机制和调整程序。避免基于不确定预测的不可逆承诺。

**系统地评估过去的预测**。哪些机构和专家预测正确了?哪些没有?这种评估很少系统地进行,但它对于随着时间推移改进机构预测至关重要。

### 理解专家声明

当遇到预测时——来自专家、分析师或媒体——应用这些过滤器:

- 预测是否足够具体以便被评估?我以后能知道它是对还是错吗?
- 预测者的追踪记录如何?他们以前做过可验证的预测吗,准确性如何?
- 什么会改变预测者的想法?如果什么都不会,这不是预测——是意识形态。
- 激励是否与准确性一致?预测者是因为正确而获得奖励,还是因为自信和令人难忘?

许多公开预测通不过这些测试。预测模糊到无论结果如何都能声称被证实。预测者没有追踪记录或记录很差但不被审视。没有什么能改变预测者的观点。自信而不是校准得到奖励。

这不是预测;这是披着预测外衣的修辞。学会区分真正的预测与预测戏剧本身就是一项有价值的技能。

---

*延伸阅读*

**Daniel Kahneman,《思考,快与慢》**。关于影响预测和判断的认知偏见的权威入门,包括计划谬误、内部/外部视角区分和基准率忽视。

**Philip Tetlock和Dan Gardner,《超级预测》**。关于什么区分了优秀预测者以及如何改进的必读著作。关于成为更好预测者最有用的单本书籍。

**Nate Silver,《信号与噪声》**。对各领域预测的通俗巡礼(天气、选举、经济),关注每个领域什么有效。

**Metaculus.com和其他预测平台**。主动练习对改进至关重要。像Metaculus、Good Judgment Open和Polymarket这样的平台提供了做出预测、接收反馈的机会。

---

*关联:本文直接建立在《概率与统计思维》(提供了表示不确定性的数学基础、更新信念的贝叶斯定理,以及基准率这一关键概念)和《因果关系》(解释了理解因果机制如何使预测成为可能)的基础上。这里发展的框架——基准率、参照类预测法、内部/外部视角区分、校准——将在《推理与问题解决》中广泛应用。*