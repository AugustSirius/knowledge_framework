# 技术与社会
*技术如何塑造人类生活*

1977年，数字设备公司创始人断言："没有任何理由让普通人在家里拥有一台电脑。" 2007年，微软CEO说iPhone定价过高，对商业客户毫无吸引力。这些预测并不愚蠢——它们出自最懂技术的人。他们没料到的是：技术与社会的互动，会产生连设计者都始料未及的结果。

印刷术催生了宗教改革，汽车塑造了郊区和石油地缘政治，社交媒体重塑了选举和心理健康。技术从不仅仅做它被设计来做的事。

这引出核心问题：技术驱动社会变革，还是社会决定技术如何发展？我们能治理技术，还是技术在治理我们？这不是学术游戏——今天关于AI、基因工程、监控系统的决定，会在几代人的时间里塑造人类生活。

## 技术与社会：一场永不停歇的双人舞

最有用的框架不是"技术决定一切"或"社会决定一切"，而是看到它们的**互相塑造**：社会选择哪些技术得到发展、如何设计；技术创造出新的可能性和限制；这些可能性又反过来改变社会。循环往复。

这能解释很多困惑：为什么技术效应超出设计初衷？为什么同样的技术在不同地方产生不同结果？为什么技术上更优越的方案有时会失败？

关键是问对问题。不要问"这项技术会产生什么影响"（好像技术是从天而降的外来物），而要问：什么社会条件孕育了这项技术？它开启或封闭了哪些可能性？谁在争夺它的使用方式？我们能用什么治理结构影响它的发展？

**三个要警惕的误区：**

**"技术是中立的，重要的是怎么用"** ——这忽视了设计选择已经嵌入了价值观。锤子可以建造也可以破坏，但监控系统很难被用来保护隐私。可能用途的范围是被设计进去的。

**"能造出来的东西一定会被部署"** ——很多技术上可行的东西从未被造出来。核武器本可以扩散得多得多，人类克隆技术存在但基本没人做。社会选择约束着技术的发展。

**"X技术的影响是什么？"** ——这种问法把技术当成外部冲击。但技术是社会生产的，在社会中部署，被社会不断修正。不是对社会的"影响"，而是社会内部的转变。

## 大辩论：是技术推动历史，还是人塑造技术？

### 技术决定论：技术是历史的引擎

这个阵营认为：技术一旦存在，其社会后果就基本不可避免。马克思说"蒸汽磨产生的是工业资本家的社会"，麦克卢汉说"媒介即信息"——传播技术的形式比内容更重要。

看看这些案例，决定论确实有说服力：

**马镫改变欧洲**：历史学家林恩·怀特认为，马镫使重骑兵成为可能，重骑兵需要大量训练和昂贵装备，这需要封建采邑制度来供养，于是产生了中世纪社会秩序。一个马镫，引发了社会革命。

**汽车重塑文明**：福特想的是卖车，结果催生了郊区、高速公路、石油依赖、零工经济，削弱了公共交通，改变了城市形态和生活方式。

**智能手机吞噬世界**：不到十五年，它成为我们与世界的主要界面。我们平均每天看手机96次，移动支付超过2万亿美元，位置追踪无处不在，零工平台雇用数百万人。

决定论的核心逻辑是**可供性**（affordances）——技术使某些行为变容易，使另一些变困难。汽车让个人高速出行变容易，但不提供高效公共交通的可能性。社交媒体让信息快速传播和社会比较变容易，但不提供深思熟虑对话的可能性。人类倾向于选阻力最小的路，所以这些可供性在大规模上塑造行为。

但决定论有明显问题：

**同样的技术，不同的结果** ——日本智能手机普及率高，但社交媒体动态与美国很不同，因为文化强调群体和谐。如果技术决定结果，应该看到更多一致性。

**技术内部也有选择** ——汽车的影响取决于道路建设、分区法规、公共交通投资的决策。洛杉矶和东京都是汽车社会，但城市形态截然不同。

**技术不是自发产生的** ——哪些技术被开发反映了社会优先级。军事资金塑造了早期计算机，广告资金塑造了社交媒体。

### 社会建构论：技术是社会的产物

建构论阵营反击：技术不能决定社会，因为技术本身是社会决定的。哪些技术被开发、如何设计、产生什么效果，都取决于社会过程。

核心洞察是**解释的弹性**：技术没有固有的意义或用途。不同群体对同一技术有不同理解，这些理解塑造了技术的发展和效果。

早期自行车就是经典案例。年轻男性追求速度（青睐高轮车），女性需要安全和实用（受限于长裙和社会期望），老年人看重稳定性。最终胜出的两轮等大安全自行车，不是物理学最优解，而是社会协商的结果。

短信服务（SMS）本是工程师设计的网络管理工具，青少年把它变成了社交媒介。互联网是为军事设计的，被学者变成知识共享网络，被企业家变成商业平台，被活动家变成组织工具。技术离开实验室时并未"完成"。

**人工物有政治性**：政治学家兰登·温纳指出，技术决策嵌入了政治价值。纽约长岛的公园道路桥梁被故意建得很低，公交车过不去，实际上把依赖公交的低收入群体排斥在海滩之外。这个人工物执行着政治安排，却不需要持续的政治决策。

但纯粹建构论也有问题：

**物质约束确实存在** ——你不能通过社会建构造出永动机。电池有能量密度极限，不以人的意志为转移。

**某些可供性是稳健的** ——汽车在任何社会都提供高速个人出行的可能性，这会产生可预测的后果。

**默认设置的力量** ——技术带着设计选择到来，大多数用户接受默认值。这赋予设计者巨大权力。

### 综合：技术动量

历史学家托马斯·休斯提出：技术与社会的关系会随时间变化。年轻的技术系统有社会可塑性，成熟的系统则发展出**动量**——积累的基础设施、训练有素的工人、制度依赖、文化实践——使改变变得困难。

电网就是例证。19世纪80年代，直流电和交流电都可行，社会和经济因素让交流电胜出。但现在电网有巨大动量：数万亿美元基础设施、围绕它建立的电力公司、以它为前提的法规、依赖它的生活方式。

休斯的洞察：决定论和建构论都对，只是在不同阶段。早期干预是高杠杆的，一旦系统成熟就会显著约束选项。

这意味着：**及早行动**。塑造AI系统的时机是现在，而不是等它嵌入每个机构之后。

## 可供性与权力：技术如何施加影响

如果技术不是中立的，它如何施加权力？通过**可供性**——设计选择鼓励某些行为、抑制另一些行为。

以社交媒体的"点赞"按钮为例。这不是中立功能。它创造了**可量化社会认可**的可能性，把模糊的赞许感受转化为一个数字，创造了基于指标的社会等级。这鼓励用户发布高互动内容（往往是愤怒或过度理想化的生活），抑制细致入微的表达。

这关联到社会学的**结构与能动性**。能动性是你自由选择的能力，结构是限制选择的安排。在物理世界，墙壁和法律是结构。在数字世界，**代码即结构**。如果平台没有"踩"按钮，你就无法表达那种情绪。如果算法优先推送视频，你作为文字作者被听到的能力就在结构上被削弱了。

说工具是中立的，就是无视工具被创造时就带有关于如何使用的**脚本**。设计了"无限滚动"的平台不是中立的——它被设计来侵蚀你停止消费的能力。

## 数字化转型：我们正在经历的革命

我们正经历一场规模可与工业化相比的转型——经济、社会、政治活动向数字平台的转移。

### 数据成为资源

工业经济围绕实物商品，数字经济围绕数据——关于行为、偏好、位置、关系的信息。

**网络效应创造赢家通吃**：有更多数据的平台提供更好服务，吸引更多用户，产生更多数据。谷歌搜索随着使用而改进。这种反馈产生的市场集中度远超工业垄断。

**监控作为商业模式**：谷歌和Meta通过提供基于用户监控的精准投放，占据全球数字广告一半以上。这创造了监控的结构性激励，个人隐私偏好难以抗衡。

**不对称的知识**：平台对用户的了解远超用户对平台的了解。Facebook在未经同意的情况下对数百万人做心理实验。算法通过我们看不见的机制塑造我们看到的内容。

### 自动化与工作

数字技术越来越多地执行过去需要人类认知的任务。争论在于：这次是否不同？过去技术变革总是在消灭旧工作的同时创造新工作，但AI代表通用的认知自动化，可能在各领域取代人类。

**被误解的卢德派**：19世纪英国纺织工人常被描绘成反技术的蠢人。错了。他们是熟练工匠，捣毁机器是集体谈判——反对的不是技术本身，而是技术引入的社会条件。今天创意领域对AI的抵制，同样是关于谁获取生产力提升价值的劳资争议。

**中间层空心化**：证据显示自动化导致工作两极分化。常规性认知和体力工作（中产阶级的行政和制造业工作）容易被自动化。留下的是高技能高薪工作和低技能低薪服务工作。技术转变正在加剧不平等。

零工平台用算法管理工人却不建立雇佣关系——把风险转嫁给工人，同时榨取效率。一个"为自己工作"的司机实际上每分每秒都被一个他们看不见、无法协商、无法申诉的算法管理。

### 公共领域碎片化

印刷术创造了民族国家的条件——让人们想象自己是阅读同一份新闻的共同体。互联网碎片化了这个共同体。

**情境坍塌**：我们向不同受众呈现不同版本的自己（家人、老板、朋友）。社交媒体把所有受众压平为一个。为了生存，用户诉诸最低公分母的自我呈现，或向圈内群体表演性表态，同时激怒圈外群体。

**注意力经济**：信息丰富，注意力稀缺。算法优先推送高唤起情绪（愤怒、恐惧、认同感）。这不是故障，这就是商业模式。结果是社会分裂成不同的现实隧道，不是因为人们愚蠢，而是因为公共领域的基础设施被优化为互动而非真相。

### 监控无处不在

肖莎娜·祖博夫创造了"监控资本主义"一词：人类经验被转化为行为数据，数据成为平台专有资产，平台用它预测行为，预测被卖给想影响行为的广告商，循环强化。

想想谷歌对你的了解：每次搜索，每封邮件，去过的每个地方，看过的每个视频。从中可以推断你的健康状况、政治观点、恋爱状态、财务状况——往往比你自己说的还准确。

**国家监控**：使商业监控成为可能的技术也使国家监控成为可能。中国的综合监控系统展示了技术如何赋能威权控制：面部识别、社会信用评分、族群追踪。

但民主国家也扩展了监控。斯诺登披露美国NSA收集几乎所有美国电话元数据，通过"棱镜"项目访问主要平台。大规模监控的基础设施在民主国家同样存在——问题是什么约束能防止滥用。

监控影响的不只是隐私，还有依赖匿名性的权利——结社、言论、政治参与。研究显示，知道被监视时人们会自我审查；对监控的意识抑制了合法言论。

## 我们能治理技术吗？

如果技术塑造社会，而技术本身由社会过程塑造，那么治理既可能也必要。

### 科林里奇困境

核心挑战是时机。大卫·科林里奇指出：技术发展早期，治理可行但影响未知；后期影响清楚了但技术已根深蒂固。

当社交媒体还年轻时，很少人预见到它对民主或心理健康的影响。现在影响更清楚了，但数十亿美元已投入，数亿人已养成习惯，整个行业都依赖现有平台。当汽车还是新事物时，城市本可以发展出不同形态。一旦根深蒂固，即使弊端清晰，替代方案也变困难。

这提示我们：

**早期且适应性的治理**——在技术成熟前制定框架，设置随效果清晰而调整的机制。

**前瞻性评估**——在干预仍可行时投资理解潜在影响。

**结构性规则**——关注结构性条件（竞争、互操作性、数据权利）而非具体应用，因为即使特定技术已根深蒂固，结构仍可改变。

### 治理路径

**预防原则**：当潜在危害严重时，在安全性确认前进行管制。欧盟GDPR默认限制数据收集，要求明确许可。

**创新推定**：除非危害得到证明，否则允许发展。美国《通信规范法》第230条保护创新免于责任，稍后处理危害。

**基于风险的监管**：集中资源在最高风险应用上。AI做医疗诊断或刑事量刑，比推荐电影需要更严格审查。

**算法问责**：要求影响重大利益的算法系统保持透明。欧盟AI法案创建风险类别，对高风险系统强制要求透明度。

### 向上游行动

治理必须在**上游**——设计阶段——干预，而不仅是下游规范使用。这包括：

- **价值敏感设计**：把伦理学家和社会学家纳入工程团队，预测社会后果
- **算法审计**：要求公开算法如何做出关于贷款、假释、招聘的决策
- **反垄断与互操作性**：打破网络效应造成的垄断，允许用户在不丢失社交图谱的情况下在平台间迁移

## 棘手挑战

### 技术解决主义陷阱

技术解决主义认为所有社会问题都有技术解决方案：犯罪？预测性警务算法。气候变化？地球工程。

这忽视了社会系统的复杂性。对社会问题施加技术"补丁"往往加剧问题或掩盖根本原因。

### 专业知识悖论

技术治理需要技术专业知识。但专业知识集中在开发者手中——而他们有弱化治理的利益。开发者比监管者更懂技术，可以塑造监管讨论、发现漏洞、以对自己有利的方式实施治理。

应对方法：建设与行业专业知识相匹配的监管能力；创建没有开发者利益冲突的独立评估机构；资助能提供反向专业知识的公共利益技术专家。

## 你能做什么

### 个人层面

理解可供性实现有意识的使用。技术不是中立工具——设计鼓励某些行为。识别这些设计让你可以顺应或对抗。

**具体做法**：
- 注意变量奖励机制（下拉刷新、通知徽章、无限滚动），它们被设计来最大化参与
- 增加有意的阻力：把应用从主屏幕移除，关闭非必要通知
- 检查并更改默认设置——它们服务平台利益，而非你的利益

### 职业层面

技术变革通过自动化、平台中介、技能需求转变影响职业。

**专注互补技能**：随着AI处理认知任务，与AI互补而非竞争的技能更有价值——在模糊情境中的判断力、在开放问题中的创造力、在人际关系中的情商。

**预期持续变化**：特定技术技能的保质期在缩短。元技能——学习能力、适应能力、驾驭模糊性——比特定技术熟练度更重要。

### 作为公民

技术是政治性的。技术选择值得民主参与，而不是委托给专家。看似锁定的轨迹可以被质疑。你想生活在什么样的社会？技术应该扮演什么角色？明确表达价值观是塑造技术使之符合这些价值观的前提。

## 未解之谜

**通用人工智能可能吗？意味着什么？** 当前AI是狭义的——在特定任务上出色，却无法进行人类轻松完成的一般推理。通用AI是否可能，对人类能动性意味着什么，存在深刻不确定性。

**平台能被民主治理吗？** 私人平台做出影响数十亿人的治理决策。它们能被问责吗？通过监管？反垄断？新的所有权模式？

**当我们将越来越多的决策委托给AI时，会失去道德推理能力吗？** 算法能展示仁慈吗？

## 综合

技术与社会互相塑造：社会选择塑造哪些技术得到发展及如何部署；技术创造结构化社会可能性的可供性；整个系统通过持续互动演化。

我们面临真正的选择——但选择受制于现有安排。我们不能简单决定拥有一个不同的技术秩序。但在约束之内，我们可以影响轨迹：通过塑造发展的治理，通过引导部署的监管，通过要求问责的集体行动，以及通过关于如何将技术融入生活的个人选择。

无论技术乐观主义（技术本质上有益）还是技术悲观主义（技术本质上威胁）都不充分。技术从社会过程中产生，具有真实效果，可以被治理——但治理困难，需要持续努力。

我们建造的技术体现了关于想要什么样社会的选择。问题是：我们是有意识地做出这些选择，还是让它们被默认地替我们做出。

---

*关联：本话题建立在社会学（话题121）基础上，理解社会结构如何塑造并被物质条件塑造。它直接关联到人工智能（话题101），因为AI可能是当前最具后果性的技术发展。这里的框架——特别是关于治理和社会建构的框架——适用于理解后续将讨论的媒体系统（话题193）和信息环境（话题239-241）。*

**字数：约4,100字**
